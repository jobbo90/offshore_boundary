year
print(paste0(wd,"/data/processed/coastlines/", aoi, '_',path_rows, '_'
'_', year, '_coastlines.csv'))
print(paste0(wd,"/data/processed/coastlines/", aoi, '_',path_rows, '_',
'_', year, '_coastlines.csv'))
mudbanks_per_year
mudbanks_per_year <- mudbanks_per_year %>%
dplyr::select(!c(x,y,
# SmoothedPeak, SmoothedPeakFract, axisDistAbs,
axisDistSlope, endDrop, maxExtent,maxExtentIndex,
meanMud, mudFract, mudFractAbs, mudFractSlope,
peakCoordX, peakCoordY,))
colnames(mudbanks_per_year)
mudbanks_per_year <- mudbanks_per_year %>%
dplyr::select(!c(x,y,
# SmoothedPeak, SmoothedPeakFract, axisDistAbs,
# axisDistSlope, endDrop, maxExtent,maxExtentIndex,
# meanMud, mudFract, mudFractAbs, mudFractSlope,
peakCoordX, peakCoordY,))
mudbanks_per_year <- mudbanks_per_year %>%
dplyr::select(!c(x,y,
# SmoothedPeak, SmoothedPeakFract, axisDistAbs,
# axisDistSlope, endDrop, maxExtent,maxExtentIndex,
# meanMud, mudFract, mudFractAbs, mudFractSlope,
# peakCoordX, peakCoordY
))
for (year in unique(format(as.Date(uniqueDates), '%Y'))){
# year <- 2000
# print(year)
start_year <- as.Date(ISOdate(year, 1, 1))
end_year <- as.Date(ISOdate(year, 12, 31))
mudbanks_per_year <-subset(mudbanks,
as.Date(DATE_ACQUIRED) >= start_year &
as.Date(DATE_ACQUIRED) <= end_year)
mudbanks_per_year <- mudbanks_per_year %>%
dplyr::select(!c(x,y,
# SmoothedPeak, SmoothedPeakFract, axisDistAbs,
# axisDistSlope, endDrop, maxExtent,maxExtentIndex,
# meanMud, mudFract, mudFractAbs, mudFractSlope,
# peakCoordX, peakCoordY
))
write_csv(mudbanks_per_year, paste0(wd,"/data/processed/coastlines/", aoi,
'_',path_rows, '_',
'_', year, '_coastlines.csv'))
print(paste0(wd,"/data/processed/coastlines/", aoi, '_',path_rows, '_',
'_', year, '_coastlines.csv'))
remove(mudbanks_per_year)
}
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("D:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
ee_Initialize()
## ---------------------------
source("./src/functions.R")
## ---------------------------
# seq1 <- seq(1985, 1999, 1)
seq2 <- seq(2015, 2020, 1)
# seq3 <- seq(2002, 2002, 1)
years <- c(seq2)# seq(from = 1985, to = 2020, by = 1)
# pos to exlcude for mudbank boundary estimates / outlier detection
posToExclude <- c(seq(138000,147000,1000),
seq(241000, 255000, 1000))
min_Std <- 25 # minimal amount of meters difference before considered outlier
year_limit <- 4 # search window in years for finding coastline obs when insufficient values per year.
min_obs_rosner <- 10    # Amount of obs per year needed to perform Rosner Test
exportCoasts <- T
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
leaflet() %>%
addProviderTiles("Esri.WorldImagery")
dataFolder <- './data/raw'
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
aoi <-  c('Braamspunt') # Suriname / Braamspunt / WegNaarZee
path_rows <- c('229_56')
filtered <- vector('list', 100)
for (q in seq_along(years)) {
for (x in seq_along(aoi)){
for (pr in path_rows){
# q <- 8
year = as.character(years[q])
region = aoi[x]
filters = c(year, region, pr)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))}
}}
filtered <- unique(filtered)
allFiles <- do.call(bind_rows, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
filtered
# all dates
uniqueDates <- unique(allFiles[,col_of_interest(allFiles, 'DATE_ACQUIRED$')]);
uniqueDates
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("D:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
ee_Initialize()
## ---------------------------
source("./src/functions.R")
## ---------------------------
# seq1 <- seq(1985, 1999, 1)
seq2 <- seq(2015, 2020, 1)
# seq3 <- seq(2002, 2002, 1)
years <- c(seq2)# seq(from = 1985, to = 2020, by = 1)
# pos to exlcude for mudbank boundary estimates / outlier detection
posToExclude <- c(seq(138000,147000,1000),
seq(241000, 255000, 1000))
min_Std <- 25 # minimal amount of meters difference before considered outlier
year_limit <- 4 # search window in years for finding coastline obs when insufficient values per year.
min_obs_rosner <- 10    # Amount of obs per year needed to perform Rosner Test
exportCoasts <- T
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
leaflet() %>%
addProviderTiles("Esri.WorldImagery")
dataFolder <- './data/raw'
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
aoi <-  c('Braamspunt') # Suriname / Braamspunt / WegNaarZee
path_rows <- c('229_56')
filtered <- vector('list', 100)
for (q in seq_along(years)) {
for (x in seq_along(aoi)){
for (pr in path_rows){
# q <- 8
year = as.character(years[q])
region = aoi[x]
filters = c(year, region, pr)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))}
}}
filtered <- unique(filtered)
allFiles <- do.call(bind_rows, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
# all dates
uniqueDates <- unique(allFiles[,col_of_interest(allFiles, 'DATE_ACQUIRED$')]);
drop <- c('system.index', '.geo')
keep_columns <- colnames(allFiles)[!(colnames(allFiles) %in% drop)]
# prep input to sf data.frame class
mudbanks <- reshape_csvPoints(allFiles, 'coastX', 'coastY', keep_columns) # 'peakCoordX', 'peakCoordY'
# coastX / coastY
# change all -1 to NA
# these are the transect that resulted in no coastline estimate
mudbanks$coastDist[mudbanks$coastX == -1] <- NA
# sort al rows based on position & date
mudbanks<-mudbanks[with(mudbanks, order(pos, DATE_ACQUIRED)), ]
# make groups per year, 3 months and 3 years per transect
mudbanks <- mudbanks %>%
mutate(quarterly_col = as.Date(cut(lubridate::date(mudbanks$DATE_ACQUIRED),
"3 month"))) %>%
mutate(date_col = as.Date(cut(lubridate::date(mudbanks$DATE_ACQUIRED),
"3 year"))) %>%
mutate(five_year_col = as.Date(cut(lubridate::date(mudbanks$DATE_ACQUIRED),
"5 year"))) %>%
mutate(year_col = as.Date(cut(lubridate::date(mudbanks$DATE_ACQUIRED),
"1 year")))
group_dates<-unique(mudbanks$year_col)        # yearly
group_pos <- unique(mudbanks$pos)             # All unique positions (transect number)
group_years <- unique(mudbanks$date_col)      # per 3 year
five_years <- unique(mudbanks$five_year_col)
# for testing / visualization define an imageCollection
collectionL4 <- ee$ImageCollection("LANDSAT/LT04/C01/T1_TOA")$
filterBounds(ee$Geometry$Point(-55.54, 5.94))
collectionL5 <- ee$ImageCollection("LANDSAT/LT05/C01/T1_TOA")$
filterBounds(ee$Geometry$Point(-55.54, 5.94))
collectionL7 <- ee$ImageCollection("LANDSAT/LE07/C01/T1_TOA")$
filterBounds(ee$Geometry$Point(-55.54, 5.94))
collectionL8 <- ee$ImageCollection("LANDSAT/LC08/C01/T1_TOA")$
filterBounds(ee$Geometry$Point(-55.54, 5.94))
collection <- collectionL8$merge(collectionL5)$merge(collectionL7)$
merge(collectionL4)
vizParams = list(
bands = c("B5", "B4", "B3"),
min = 0.05, max = 0.5, gamma = 1.4
)
#'
#'  estimate coastal outliers with rosner test
#'  - for each transect per 3 years to ensure sufficient observations
#'
#'  Still poses problems for some transects
#'  Resulting in negative mudbank distances, especially at transects
#'  near river mouths.
#'  Also test for years with low obs?! 1985 - 2000
# assume nothing is outlier and set outputs to NA
mudbanks$coast_outlier <- 1
mudbanks$slope         <- NA
mudbanks$coastObs      <- NA
for(i in group_years){ # group_years / five_years
start <- Sys.time()
# i<-five_years[five_years == c("1991-01-01")]
for(q in group_pos){
# q <- group_pos[group_pos == 116000]
indexs <- which(mudbanks$date_col == i &  # five_year_col
mudbanks$pos == q &
mudbanks$coastX != -1)
subsets3 <- mudbanks[indexs, ]
# get nearest observation and add it to the list
# is .na going to throw a problem?
reference_date <- mean(as.Date(subsets3$DATE_ACQUIRED))
# Aamount of obs
# obs_3years <- nrow(subsets3)
# update that if subset per year is to small, include extra observations?
# So grow the subset to at least 10(?) obs by adding nearest observations
maxAttemp <- 0 # make sure you don't get stuck in infinite loop..
while(nrow(subsets3) < min_obs_rosner &
# nrow(subsets3)+obs_3years > min_obs_rosner &
maxAttemp < min_obs_rosner+5){
# exclude dates from the year of interest
# sample from entire dataset so that years outside the 3 year block
# are also possible candidates
# pitfall: any date is possible, also the ones to far away
# so set limit at search window of x years?
selectedDates <- subset(mudbanks, mudbanks$pos == q &
mudbanks$coastX != -1 &
!(mudbanks$DATE_ACQUIRED %in%
subsets3$DATE_ACQUIRED)
)$DATE_ACQUIRED
# exclude the ones already selected
# are NA a problem that seems to throw warnings()?
nearestDate <- selectedDates[1:length(selectedDates) ==
which.min(replace(abs(as.Date(selectedDates) - reference_date),
abs(as.Date(selectedDates) - reference_date)>year_limit*356, NA))]
# if nothing is found, break the loop
if(length(nearestDate) == 0){break}
index_nearest <- which(as.Date(as.character(mudbanks$DATE_ACQUIRED)) == nearestDate &
mudbanks$pos == q &
mudbanks$coastX != -1)
# update subsets
subsets3 <- rbind(subsets3, mudbanks[index_nearest, ] )
maxAttemp = maxAttemp + 1
}
# because subsets 3 changed in size, recalc the indices.
subsets3_recal <- which(mudbanks$DATE_ACQUIRED %in% subsets3$DATE_ACQUIRED &
mudbanks$pos == q &
mudbanks$coastX != -1)
# apply rosner test if there is sufficient observations ==> this implies that the timeseries to look at needs to be larger than 3 years.
# also the year limit needs to go up.
# All detected outliers with larger std value recieve outlier == 0
# Only give the rosner output to the original subset3 indices
mudbanks[indexs, 'coast_outlier'] <-
rosner(subsets3$coastDist,min_Std , min_obs_rosner)[which(subsets3_recal %in% indexs)]
# Will throw an error/warning if all values are the same => nothing is assigned as outlier
# plot(as.Date(subsets3$DATE_ACQUIRED), subsets3$coastDist,
# main = paste0(q), xlab = 'date', ylab = 'coastline position [m]')
# points(as.Date(subsets3$DATE_ACQUIRED)[which(rosner(subsets3$coastDist, min_Std, min_obs_rosner) == 0)],
# subsets3$coastDist[which(rosner(subsets3$coastDist, min_Std, min_obs_rosner) == 0)],
# col = 'red')
}
suppressWarnings(remove(subsets3, indexs, reference_date,
selectedDates, nearestDate, index_nearest,
subsets3_recal))
end <- Sys.time()
dif<- difftime(end, start, "mins")
print(paste0(as.Date(i) ,' in ', round(dif,1), ' in ', units(dif)))
}
#'
#'  calculate slope of coastline change
#'  - Per year
#'  - include nearest observations
#'  -
#'  within predefined search window (4 years difference max)
#'
for(i in group_dates){
start <- Sys.time()
for(q in group_pos){
# i<-group_dates[group_dates == c("2017-01-01")]
#
# q <- group_pos[group_pos == 16530]
# print(q)
subsets_annual <- mudbanks[which(mudbanks$year_col == i &
mudbanks$pos == q &
mudbanks$coastDist > -1), ]
# select outliers & non outliers
outliers <- subset(subsets_annual, coast_outlier == 0)
nonOutliers <- subset(subsets_annual, coast_outlier == 1)
# get nearest observation and add it to the list
# if there is nothing there; half way through the year
reference_date <- as.Date(ifelse(nrow(nonOutliers)>0,
mean(as.Date(nonOutliers$DATE_ACQUIRED)),
as.Date(i)+days(180)))
# improvement required!
# slope is only applicable if quality of coastline estimate is
# sufficient (see landsat 7 case with no data in wetland areas)
# if outlier detection is sufficient the slope can be correctly estimated
# if  there is insufficient observations;
# search for additional observations to calculate the slope
# downside; if the observations that are detected are of good quality,
# the slope is wronfully adjusted based on neighbouring observations
# resulting in wrong estimate (often underestimate!) of rate of change.
maxAttemp <- 0
while(nrow(nonOutliers) < 8 &
maxAttemp < min_obs_rosner){
# exclude the ones from the original year
selectDates <- subset(mudbanks, mudbanks$pos == q &
mudbanks$coastDist > -1 & !(mudbanks$DATE_ACQUIRED %in%
nonOutliers$DATE_ACQUIRED))$DATE_ACQUIRED
# get nearest date (excluding dates outside limit)
nearestDate <- selectDates[1:length(selectDates) ==
which.min(replace(abs(as.Date(selectDates) - reference_date),
abs(as.Date(selectDates) - reference_date)>year_limit*356, NA))]
if(length(nearestDate) == 0){break}
index_nearest <- which(as.Date(as.character(mudbanks$DATE_ACQUIRED)) == nearestDate &
mudbanks$pos == q &
mudbanks$coastDist > -1 &
mudbanks$coast_outlier == 1)
# update annual subset
nonOutliers <- rbind(nonOutliers, mudbanks[index_nearest, ] )
maxAttemp = maxAttemp + 1
}
# only fit a line if there is a least 5 valid observations.
if(nrow(nonOutliers) < 5){
m_per_year <- NA
} else {
# calculate linear fit
lm.out <- lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED)))
# intercept <-lm.out$coefficients[1]
slope <- round(lm.out$coefficients[2], 5) # change per unit of x (=days)
m_per_year <- slope*365
}
# update all slope values from the original years (incl. coastdist -1 and outliers)
mudbanks$slope[which(mudbanks$year_col == i &
mudbanks$pos == q)] <- as.numeric(m_per_year)
mudbanks$coastObs[which(mudbanks$year_col == i &
mudbanks$pos == q)] <- as.numeric(nrow(nonOutliers))
}
# remove temp variables
suppressWarnings(remove(subsets_annual, outliers,nonOutliers, reference_date,
maxAttemp, lm.out, slope, m_per_year))
end <- Sys.time()
dif<- difftime(end, start, "mins")
print(paste0(as.Date(i) ,' in ', round(dif,1), ' in ', units(dif)))
# plot(as.Date(nonOutliers$DATE_ACQUIRED), nonOutliers$coastDist,
#   main = paste0(q), xlab = paste0(i), ylab = 'coastline position',
#   ylim=c(min(nonOutliers$coastDist)-30,max(nonOutliers$coastDist)+30),
#   xlim=c(min(as.Date(nonOutliers$DATE_ACQUIRED)),
#         max(as.Date(nonOutliers$DATE_ACQUIRED))))
# points(as.Date(outliers$DATE_ACQUIRED), outliers$coastDist, col = 'red')
# abline(lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED))),lty = 2)
# text(min(as.Date(subsets_annual$DATE_ACQUIRED)) + 90,
#      max(subsets_annual$coastDist) + 25, paste0('slope = ', m_per_year, ' meter'))
}
#'
#'  Last observation carried forward
#'  - for observations that are outlier / NA
#'
# set initial value
mudbanks$locf <- mudbanks$coastDist
# if coastDist NA or coast observation is an outlier;
indices <- unique(which(is.na(mudbanks$coastDist) | mudbanks$coast_outlier == 0))
for(ind in indices){
# ind<-indices[1200]
data_entry <- mudbanks[ind, ]
# select all accepted observations from the same transect
pos_subset <- subset(mudbanks, mudbanks$pos == data_entry$pos &
mudbanks$coast_outlier == 1 &
!is.na(mudbanks$coastDist))
# plot(pos_subset$DATE_ACQUIRED, pos_subset$locf)
# plot(pos_subset$DATE_ACQUIRED, pos_subset$coastDist, col = 'red')
if(nrow(pos_subset) > 0){ # if no observations; locf remains original observation (=NA)
# calculate date difference
dateDiff <- abs(as.Date(pos_subset$DATE_ACQUIRED) - as.Date(data_entry$DATE_ACQUIRED))
# find nearest date
dateDiff[dateDiff==0] <- max(dateDiff) # exclude the date of interest (dateDiff = 0)
minInd <- which.min(dateDiff)
nearest <- pos_subset[minInd,]
# fill locf in original data frame
mudbanks[row.names(mudbanks) == row.names(data_entry), 'locf'] <-
nearest$coastDist
}
}
#'
#' Coastline
#' - median distance from transect origin per year
#' -
#'
# order by pos
mudbanks<-mudbanks[order(mudbanks$pos),]
# calculate median coastal position
# grouped by pos, year and outlier
mudbanks <- mudbanks %>%
dplyr::group_by(pos, year_col, coast_outlier) %>%
dplyr::mutate(coast_median = median(coastDist, na.rm = T))
# set outlier groups to NA
# this is now prefered over filling NA with nearest values.
mudbanks$coast_median[mudbanks$coast_outlier == 0] <- NA
# key to indicate groups of years~pos
mudbanks$key <- with(rle(as.numeric(mudbanks$year_col)), rep(seq_along(lengths), lengths))
# # fill outliers (NA) with median coastal observation of that year
mudbanks <- mudbanks %>%
group_by(key) %>% # group by position & year
mutate(coast_median = Mode(coast_median)) %>%
ungroup() # remove group
#fill(coast_median) #%>%      # fill NA with group value ==> fill uses one down or one up and will still have NA's if next is NA
#'
#'  calculate for each pos, each year gain/loss compared to previous year
#'
mudbanks <- mudbanks %>%
group_by(pos) %>%           # group_by performs calculation per group
# arrange(pos) %>%              # for each pos calculate the difference compared to previous median observation
# calculate for each position the difference with previous
mutate(deltaCoast = coast_median - lag(coast_median)) %>%
mutate(deltaCoast = replace_na(deltaCoast, 0)) %>%        # NA corresponds to first obs at each transect, set it to 0
# make sure within each group the difference are all assigned the same value (max)
group_by(key) %>%
mutate(deltaCoast = ifelse(sign(deltaCoast[which.max(abs(deltaCoast))]) == 1,
max((deltaCoast), na.rm = F),
min((deltaCoast), na.rm = F))) %>%
ungroup()
if(exportCoasts){
for (year in unique(format(as.Date(uniqueDates), '%Y'))){
# year <- 2000
# print(year)
start_year <- as.Date(ISOdate(year, 1, 1))
end_year <- as.Date(ISOdate(year, 12, 31))
mudbanks_per_year <-subset(mudbanks,
as.Date(DATE_ACQUIRED) >= start_year &
as.Date(DATE_ACQUIRED) <= end_year)
mudbanks_per_year <- mudbanks_per_year %>%
dplyr::select(!c(x,y,
# SmoothedPeak, SmoothedPeakFract, axisDistAbs,
# axisDistSlope, endDrop, maxExtent,maxExtentIndex,
# meanMud, mudFract, mudFractAbs, mudFractSlope,
# peakCoordX, peakCoordY
))
write_csv(mudbanks_per_year, paste0(wd,"/data/processed/coastlines/", aoi,
'_',path_rows, '_',
'_', year, '_coastlines.csv'))
print(paste0(wd,"/data/processed/coastlines/", aoi, '_',path_rows, '_',
'_', year, '_coastlines.csv'))
remove(mudbanks_per_year)
}
}
