years <- c('2018', '2019')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
folderSelect
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
df
years <- c('2009')#c('2018', '2019')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
filtered <- vector('list', 100)
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
filtered
filtered <- unique(filtered)[1:2,]
filtered
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
allFiles
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
allFiles
filtered
filtered <- vector('list', 100)
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
filtered
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
col_dates <- col_of_interest(allFiles, 'DATE_ACQUIRED$')
col_coastDist <- col_of_interest(allFiles, 'coastDist$')
# all unique dates
uniqueDates <- unique(allFiles[,col_dates]);
uniqueDates
# all unique transect (id's)
pos <- unique(allFiles[, col_of_interest(allFiles, 'pos$')]);
uniqueX<- unique(allFiles[, col_of_interest(allFiles, 'originX$')]);
uniqueY<- unique(allFiles[, col_of_interest(allFiles, 'originY$')]);
geo<- unique(allFiles[, col_of_interest(allFiles, '.geo')]);
# test simple 2d plot coastline dist
pos_to_test <- c('236000') # 236000: loss example / 187000: gain example with clear outliers
testPos <- subset(allFiles, allFiles[,col_of_interest(allFiles, 'pos')] == pos_to_test
& allFiles[,col_of_interest(allFiles, 'coastDist$')] >= 0 )
testPos <- testPos[order(testPos$DATE_ACQUIRED),] #order by date
# or on all entries
allFiles_gt0 <- subset(arrange(allFiles, pos, DATE_ACQUIRED), coastDist >=0)
# make groups of 3 months per transect
test_allFiles <- allFiles_gt0 %>%
mutate(date_col = as.POSIXct(cut(lubridate::date(allFiles_gt0$DATE_ACQUIRED), "3 months"))) %>%
mutate(year_col = as.POSIXct(cut(lubridate::date(allFiles_gt0$DATE_ACQUIRED), "3 year")))
group_dates<-unique(test_allFiles$year_col)
group_pos <- unique(test_allFiles$pos)
# assume nothing is outlier
test_allFiles$outlier <- 1
# estimate outliers
for(i in group_dates){
# i<-group_dates[group_dates == c("2017-01-01")]
for(q in group_pos){
# q <- group_pos[group_pos == pos_to_test]
subsets <- subset(test_allFiles, year_col == i & pos == q)
# plot(as.Date(subsets$DATE_ACQUIRED), subsets$coastDist)
rownr <- strtoi(rownames(subset(test_allFiles, year_col == i & pos == q)))
# detect outliers (give them a 0!!!)
test_allFiles[rownr, 'outlier'] <- rosner(subsets$coastDist)
}
}
# plot per group after removing outliers
# check i group_by actually removes the outliers!
test_allFiles_mn <- test_allFiles %>% group_by(pos, date_col, outlier) %>%
mutate(mn = median(coastDist)) #%>%
testSubset <- subset(test_allFiles_mn,
pos == pos_to_test)
outliers <- subset(testSubset, outlier == 0)
nonOutliers <- subset(testSubset, outlier == 1)
plot(as.Date(nonOutliers$DATE_ACQUIRED), nonOutliers$coastDist, ylim = c(min(testSubset$coastDist)-30,max(testSubset$coastDist)+ 30))
points(as.Date(outliers$DATE_ACQUIRED), outliers$coastDist, col = 'red')
points(as.Date(outliers$DATE_ACQUIRED), outliers$coastDist, col = 'red')
# median values with steps per 3 months ()
points(as.Date(nonOutliers$date_col), nonOutliers$mn, col = 'blue')
# # get for all transects an oldest coastline observation as baseline
test_allFiles_mn$baseline <- 0
test_allFiles_mn$slope <- -1
reference_date <- as.Date("2017-01-01")
for (sid in pos) {
# sid = pos_to_test
# print(sid)
i <- test_allFiles_mn$pos == sid # create a logical index
# get min date with an observation
subsetTemp2 <- subset(test_allFiles_mn, test_allFiles_mn$pos == sid &
test_allFiles_mn$coastDist >= 0)
# test_allFiles_mn$outlier != 0) # exclude detected outliers
outliers <- subset(subsetTemp2, outlier == 0)
nonOutliers <- subset(subsetTemp2, outlier == 1)
# plot(as.Date(subsetTemp2$DATE_ACQUIRED), subsetTemp2$coastDist,ylim = c(min(subsetTemp2$coastDist)-30,max(subsetTemp2$coastDist)+ 30))
# points(as.Date(nonOutliers$DATE_ACQUIRED), nonOutliers$coastDist, col = 'green')
# points(as.Date(outliers$DATE_ACQUIRED), outliers$coastDist, col = 'red')
# you'd want to normalize for the coastline position around the reference date
# get first date after reference date:
index <- which.min(abs(as.Date(nonOutliers$DATE_ACQUIRED)-reference_date))
if(nrow(subsetTemp2) == 0){
coastObs <- 0
slope <- 0
} else {
coastObs <- subsetTemp2[index, 'coastDist']
lm.out <- lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED)))
intercept <-lm.out$coefficients[1]
slope <- lm.out$coefficients[2]
# residuals
resid <- lm.out$residuals
maxResid <- which.max(abs(resid))
# points(as.Date(nonOutliers$DATE_ACQUIRED[maxResid]), nonOutliers$coastDist[maxResid], col = 'purple')
# firstSubset <- nonOutliers[1:maxResid,]
# secondSubset <- nonOutliers[maxResid:nrow(nonOutliers),]
#
# firstSubset_lm <- lm(firstSubset$coastDist~as.numeric(as.Date(firstSubset$DATE_ACQUIRED)))
# secondSubset_lm <- lm(secondSubset$coastDist~as.numeric(as.Date(secondSubset$DATE_ACQUIRED)))
# firstSubset_est <- firstSubset_lm$coefficients[1] + as.numeric(as.Date(nonOutliers$DATE_ACQUIRED)) * firstSubset_lm$coefficients[2]
estimated <- intercept + (as.numeric(as.Date(nonOutliers$DATE_ACQUIRED))*slope)
# plot the fitted line
# abline(lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED))),
# lty = 2)
# abline(lm(firstSubset$coastDist~as.numeric(as.Date(firstSubset$DATE_ACQUIRED))),
#        lty = 2)
# abline(lm(secondSubset$coastDist~as.numeric(as.Date(secondSubset$DATE_ACQUIRED))),
# lty = 2)
# use identify when necesary!
# date <- identify(as.Date(subsetTemp2$DATE_ACQUIRED), subsetTemp2$coastDist, n=1, labels=as.Date(subsetTemp2$DATE_ACQUIRED))
# coastObs <- subsetTemp2[subsetTemp2$DATE_ACQUIRED == min(subsetTemp2[, 'DATE_ACQUIRED']), 'coastDist']
}
test_allFiles_mn$baseline[i] <- as.numeric(coastObs)
test_allFiles_mn$slope[i] <- as.numeric(slope)
}
# subtract each that values from each obs (ensure positive values)
# to normalize
test_allFiles_mn$normalized <- test_allFiles_mn$coastDist - test_allFiles_mn$baseline
test_allFiles_mn$mn_normalized <- test_allFiles_mn$mn - test_allFiles_mn$baseline
allFiles_mutate <- test_allFiles_mn %>% mutate(year = year(DATE_ACQUIRED),
month = month(DATE_ACQUIRED, label=TRUE),
day = day(DATE_ACQUIRED),
full_date= date(DATE_ACQUIRED),
full_date2= date(date_col))
allFiles_mutate <- allFiles_mutate %>%
filter(!(coastDist == -1) & outlier == 0) # filter outliers & negative coastal distances
labeled.dat <- allFiles_mutate[allFiles_mutate$pos %in% c('151000') ,]
p <-ggplot(allFiles_mutate,aes(x = pos,y = full_date2, fill=mn_normalized))+
geom_tile(color= "white",size=0.1) +
# scale_fill_gradientn(colours=topo.colors(7),#na.value = "transparent",
#                      breaks=c(0,median(allFiles_mutate$coastDist)),
#                      labels=c("Minimum","Maximum"),
#                      limits=c(0,median(allFiles_mutate$coastDist)))
scale_fill_viridis(name="Max Distance",option ="C", limits = c(-500, 500), oob = scales::squish)
p
pos_to_test
sid = pos_to_test
# sid = pos_to_test
# print(sid)
i <- test_allFiles_mn$pos == sid # create a logical index
i
# get min date with an observation
subsetTemp2 <- subset(test_allFiles_mn, test_allFiles_mn$pos == sid &
test_allFiles_mn$coastDist >= 0)
# test_allFiles_mn$outlier != 0) # exclude detected outliers
outliers <- subset(subsetTemp2, outlier == 0)
nonOutliers <- subset(subsetTemp2, outlier == 1)
plot(as.Date(subsetTemp2$DATE_ACQUIRED), subsetTemp2$coastDist,ylim = c(min(subsetTemp2$coastDist)-30,max(subsetTemp2$coastDist)+ 30))
# plot(as.Date(subsetTemp2$DATE_ACQUIRED), subsetTemp2$coastDist,ylim = c(min(subsetTemp2$coastDist)-30,max(subsetTemp2$coastDist)+ 30))
points(as.Date(nonOutliers$DATE_ACQUIRED), nonOutliers$coastDist, col = 'green')
pos
uniqueDates
# plot(as.Date(subsetTemp2$DATE_ACQUIRED), subsetTemp2$coastDist,ylim = c(min(subsetTemp2$coastDist)-30,max(subsetTemp2$coastDist)+ 30))
# points(as.Date(nonOutliers$DATE_ACQUIRED), nonOutliers$coastDist, col = 'green')
points(as.Date(outliers$DATE_ACQUIRED), outliers$coastDist, col = 'red')
# you'd want to normalize for the coastline position around the reference date
# get first date after reference date:
index <- which.min(abs(as.Date(nonOutliers$DATE_ACQUIRED)-reference_date))
index
lm.out <- lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED)))
intercept <-lm.out$coefficients[1]
slope <- lm.out$coefficients[2]
# residuals
resid <- lm.out$residuals
maxResid <- which.max(abs(resid))
points(as.Date(nonOutliers$DATE_ACQUIRED[maxResid]), nonOutliers$coastDist[maxResid], col = 'purple')
estimated <- intercept + (as.numeric(as.Date(nonOutliers$DATE_ACQUIRED))*slope)
# plot the fitted line
abline(lm(nonOutliers$coastDist~as.numeric(as.Date(nonOutliers$DATE_ACQUIRED))),
lty = 2)
testAll <- reshape_csvPoints(allFiles, 'coastX', 'coastY')
awd
testAll <- reshape_csvPoints(allFiles, 'coastX', 'coastY')
View(testAll)
mapview(testAll, col.regions = c("red"), layer.name = c("set1"))
coastlines <- reshape_csvPoints(allFiles, 'coastX', 'coastY')
coastlines$DATE_ACQUIRED == uniqueDates[1]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == uniqueDates[1] &
test_allFiles_mn$coastDist >= 0)
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == uniqueDates[1] &
test_allFiles_mn$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = uniqueDates[1])
mudbanks <- reshape_csvPoints(allFiles, 'peakCoordX', 'peakCoordY')
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == uniqueDates[1] &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == uniqueDates[1] &
mudbanks$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == uniqueDates[1] &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = uniqueDates[1]) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = uniqueDates[1])
for (i in uniqueDates){
print(i)
}
for (i in uniqueDates){
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == uniqueDates[i] &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == uniqueDates[i] &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = uniqueDates[i]) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = uniqueDates[i])
}
for (i in uniqueDates){
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
}
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
i <- 2
# i <- 2
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
i
for (i in uniqueDates){
# i <- uniqueDates == i
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
}
i
uniqueDates[1]
i <- uniqueDates[2]
# i <- uniqueDates[2]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
i <- uniqueDates[3]
# i <- uniqueDates[3]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
i <- uniqueDates[4]
# i <- uniqueDates[4]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
i <- uniqueDates[5]
# i <- uniqueDates[5]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
# i <- uniqueDates[6]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
i <- uniqueDates[6]
i
# i <- uniqueDates[6]
coastlines_selection <-subset(coastlines, coastlines$DATE_ACQUIRED == i &
coastlines$coastDist >= 0)
mudbanks_selection <-subset(mudbanks, mudbanks$DATE_ACQUIRED == i &
mudbanks$coastDist >= 0)
mapview(coastlines_selection, col.regions = c("red"), layer.name = i) +
mapview(mudbanks_selection, col.regions = c("green"), layer.name = i )
ee_Initialize()
# # library(plyr)
# # library(ggridges)
# remotes::install_github("r-spatial/rgee")
# remove.packages('Rcpp')
library(rgee)
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
ee_Initialize()
## ---------------------------
source("./src/functions.R")
## ---------------------------
dataFolder <- './data/raw'
# transect  <- readOGR(paste0(dataFolder, '/transects'), '2009_WnZ_transect')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports/testImages'), full.names = T))
# metaMatrix <- as.matrix(list.files(folderSelect, pattern=".csv", full.names = T))
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
# csv <- data.frame(matrix(NA, 0, 18),
#            stringsAsFactors=F)
#
# for (q in nrow(df)){
#   # q = 2
#   csv <- rbind(csv, as.matrix(read.csv2(as.character(df[q,1]),
#                       header = T, sep = ',', na.strings=c("","NA"))))
#
# }
# strings to compare
# set1 <- 'Suriname_229_56_2009_till_2009_testImage2009115'
# set2 <- 'Suriname_229_56_2009_till_2009_testImage2009115_extraMask'
# set1 <- 'Suriname_229_56_2009_till_2009_testImage20091115_extraMask_V20201207'
# set2 <- 'Suriname_229_56_2009_till_2009_testImage20091115_extraMask_largestDrop'
# largest, relative and slope drop for 20091115 image
set2 <- 'Suriname_229_56_2009_till_2009_testImage20091115_relativeDrop_20201217'
# set3 <- 'Suriname_229_56_2009_till_2009_testImage20091115_relativeDrop_20201210'
# set3 <- 'Suriname_229_56_2009_till_2009_testImage20091115_slopeDrop_20201210'
# set3 <- 'Suriname_229_56_2009_till_2009_testImage20091115_relativeDrop_20201210'
# largest, relative and slope drop for 20090912 image
# set1 <- 'Suriname_229_56_2009_till_2009_testImage20090912_largestDrop_20201210'
# set3 <- 'Suriname_229_56_2009_till_2009_testImage20090912_relativeDrop_20201210'
set1 <- 'Suriname_229_56_2009_till_2009_testImage20090912_relativeDrop_20201217'
# set3 <- 'Suriname_229_56_2009_till_2009_testImage20090912_extraMask_largestDrop'
# set2 <- 'Suriname_229_56_2009_till_2009_testImage20090912_extraMask_V20201207'
csv1 = as.matrix(read.csv2(as.character(df[grep(set1, folderSelect, ignore.case = T),1]),
header = T, sep = ',', na.strings=c("","NA"))) # rewrite as matrix to read columns as numeric values
csv2 = as.matrix(read.csv2(as.character(df[grep(set2, folderSelect, ignore.case = T),1]),
header = T, sep = ',', na.strings=c("","NA"))) # rewrite as matrix to read columns as numeric values
# csv3 = as.matrix(read.csv2(as.character(df[grep(set3, folderSelect, ignore.case = T),1]),
#                            header = T, sep = ',', na.strings=c("","NA"))) # rewrite as matrix to read columns as numeric values
#
csv1[order(csv1[,'pos']),]
# plot(csv1[,'pos'],csv1[,'mudFract'])
points1<- reshape_csvPoints(csv1, 'peakCoordX', 'peakCoordY')
# # plot test
points1_df <- points1 %>% st_drop_geometry()
# points1_df$pos <- as.numeric(points1_df$pos)
# points1_df[order(points1_df$pos),]
# plot(points1_df_order$pos, points1_df_order$mudFract)
pointsLand1 <- reshape_csvPoints(csv1, 'coastX', 'coastY')
points2<- reshape_csvPoints(csv2, 'peakCoordX', 'peakCoordY')
pointsLand2 <- reshape_csvPoints(csv2, 'coastX', 'coastY')
# points3<- reshape_csvPoints(csv3, 'peakCoordX', 'peakCoordY')
# pointsLand3 <- reshape_csvPoints(csv3, 'coastX', 'coastY')
# filter -1?
lines1 <- reshape_csvLines(csv1)
# change format of lines
lines_sf <- st_as_sf(lines1)
# ee_clean_pyenv()
# ee_install()
# # ee_install_upgrade(version = "0.1.224")
# Sys.getenv('EARTHENGINE_PYTHON'):
# "C:\\Users\\5600944\\AppData\\Local\\r-miniconda\\envs\\rgee\\python.exe"
# Load an image.
image20090912 <- ee$Image("LANDSAT/LT05/C01/T1_TOA/LT05_229056_20090912")
image20091115 <- ee$Image("LANDSAT/LT05/C01/T1_TOA/LT05_229056_20091115")
vizParams <- list(
bands = c("B5", "B4", "B3"),
min = 0.05, max = 0.4, gamma = 1.4
)
test1 <- Map$addLayer(image20090912, vizParams, "Landsat 8 20090912")
test2 <- Map$addLayer(image20091115, vizParams, "Landsat 8 20091115")
test1 + test2 +
# mapview(pointsLand2,col.regions = c("blue")) +
mapview(points1, col.regions = c("red"), layer.name = c("set1")) +
mapview(points2, col.regions = c("green"), layer.name = c("set2")) +
# mapview(points3, col.regions = c("yellow"), layer.name = c("set3")) +
mapview(lines_sf,xcol = "x", ycol = "y")
# ee_clean_pyenv()
# ee_install()
# ee_install_upgrade(version = "0.1.224")
Sys.getenv('EARTHENGINE_PYTHON'):
# "C:\\Users\\5600944\\AppData\\Local\\r-miniconda\\envs\\rgee\\python.exe"
# Load an image.
image20090912 <- ee$Image("LANDSAT/LT05/C01/T1_TOA/LT05_229056_20090912")
# ee_clean_pyenv()
# ee_install()
# ee_install_upgrade(version = "0.1.224")
Sys.getenv('EARTHENGINE_PYTHON'):
# "C:\\Users\\5600944\\AppData\\Local\\r-miniconda\\envs\\rgee\\python.exe"
# Load an image.
image20090912 <- ee$Image("LANDSAT/LT05/C01/T1_TOA/LT05_229056_20090912")
Sys.getenv('EARTHENGINE_PYTHON'):
Sys.getenv('EARTHENGINE_PYTHON')
# ee_clean_pyenv()
# ee_install()
ee_install_upgrade(version = "0.1.224")
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
ee_Initialize()
