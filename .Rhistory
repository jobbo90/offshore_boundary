library(mapview)
test1 +
mapview(pointsLand2,col.regions = c("blue")) +
mapview(points1, col.regions = c("red"), layer.name = c("set1")) +
mapview(points2, col.regions = c("green"), layer.name = c("set2")) +
mapview(points3, col.regions = c("yellow"), layer.name = c("set3")) +
mapview(lines_sf,xcol = "x", ycol = "y")
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
## ---------------------------
source("./src/functions.R")
## ---------------------------
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
dataFolder <- './data/raw'
years <- c('2018', '2019')
# transect  <- readOGR(paste0(dataFolder, '/transects'), '2009_WnZ_transect')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
filtered <- vector('list', 100)
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
filtered <- unique(filtered)[1:2,]
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
dates <- col_of_interest(allFiles, 'DATE_ACQUIRED$')
coastDist <- col_of_interest(allFiles, 'coastDist$')
# all unique dates
uniqueDates <- unique(allFiles[,dates]);
# all unique transect (id's)
pos <- unique(allFiles[, col_of_interest(allFiles, 'pos$')]);
uniqueX<- unique(allFiles[, col_of_interest(allFiles, 'originX$')]);
uniqueY<- unique(allFiles[, col_of_interest(allFiles, 'originY$')]);
geo<- unique(allFiles[, col_of_interest(allFiles, '.geo')]);
# test simple 2d plot coastline dist
pos_to_test <- c('199000')
testPos <- subset(allFiles, allFiles[,col_of_interest(allFiles, 'pos')] == pos_to_test
& allFiles[,col_of_interest(allFiles, 'coastDist$')] >= 0 )
testPos <- testPos[order(testPos$DATE_ACQUIRED),] #order by date
# # outlier detection: quantiles (tricky for large temporal range?)
# lower_bound <- quantile(testPos$coastDist, 0.025)
# upper_bound <- quantile(testPos$coastDist, 0.975)
# # # indices that are between quantiles
# ind <- which(testPos$coastDist > lower_bound & testPos$coastDist < upper_bound)
# plot date & coastline Distance
plot(as.Date(testPos$DATE_ACQUIRED),testPos$coastDist)
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
## ---------------------------
source("./src/functions.R")
## ---------------------------
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
dataFolder <- './data/raw'
years <- c('2018', '2019')
# transect  <- readOGR(paste0(dataFolder, '/transects'), '2009_WnZ_transect')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
filtered <- vector('list', 100)
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
filtered <- unique(filtered)[1:2,]
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
dates <- col_of_interest(allFiles, 'DATE_ACQUIRED$')
coastDist <- col_of_interest(allFiles, 'coastDist$')
# all unique dates
uniqueDates <- unique(allFiles[,dates]);
# all unique transect (id's)
pos <- unique(allFiles[, col_of_interest(allFiles, 'pos$')]);
uniqueX<- unique(allFiles[, col_of_interest(allFiles, 'originX$')]);
uniqueY<- unique(allFiles[, col_of_interest(allFiles, 'originY$')]);
geo<- unique(allFiles[, col_of_interest(allFiles, '.geo')]);
# test simple 2d plot coastline dist
pos_to_test <- c('199000')
testPos <- subset(allFiles, allFiles[,col_of_interest(allFiles, 'pos')] == pos_to_test
& allFiles[,col_of_interest(allFiles, 'coastDist$')] >= 0 )
testPos <- testPos[order(testPos$DATE_ACQUIRED),] #order by date
# # outlier detection: quantiles (tricky for large temporal range?)
# lower_bound <- quantile(testPos$coastDist, 0.025)
# upper_bound <- quantile(testPos$coastDist, 0.975)
# # # indices that are between quantiles
# ind <- which(testPos$coastDist > lower_bound & testPos$coastDist < upper_bound)
# plot date & coastline Distance
plot(as.Date(testPos$DATE_ACQUIRED),testPos$coastDist)
View(testPos)
# set settings
setwd("D:/WOTRO/Research/Software/Scripts/R_script/transects_tessa/R_scripts")
list.files()
list.files()[1]
CSV2019=list.files()[1]
#"U:/Suriname/R/transects_tessa/data/PointsMerge2019ALL_csv.csv"
read2019=read.csv(CSV2019, header = TRUE, ",")
read2019
#plot all transects. Col9=distance, col7=Z
plot(read2019[,9], read2019[,7])   #not yet divided into separate series
#plot one transect
i=1
listTransectNumber=(unique(read2019$TransectNr))
for (i in listTransectNumber){
oneTransect = read2019 %>% filter(TransectNr == i)
plot(oneTransect[,9], oneTransect[,7])
id <- identify(oneTransect[,9], oneTransect[,7], n=2, labels=oneTransect[,9])
abline(v = oneTransect[id[1],9])
abline(v = oneTransect[id[2],9])
yline = min(oneTransect[c(id[1],id[2]), 7])
abline(h= yline)
channel <- oneTransect[id[1]:id[2], 7]
channel
#points(oneTransect[id[1]:id[2]], channel, col = 'red')
# calculate width between 2 channel edges in meters
widthA <- (max(oneTransect[id[1]:id[2],9])-min(oneTransect[id[1]:id[2],9]))/1000
widthA
# calculate index of deepest point in meters
depth <- min(oneTransect[id[1]:id[2],7])
depth
abline(h = depth)
# get corresponding x-axis value
#indexOfDepth <- subset(oneTransect[,1], oneTransect[,7] == depth)
#indexOfDepth
# calculate area (only below level of lowest bank) in meters^2
lowestBank <- min(oneTransect[c(id[1],id[2]), 7])
spacing <- 0.025
output <- data.frame(matrix(NA, length(channel),1))
for (n in 1:length(channel)){
# n = 1
localdepth=ifelse(lowestBank-channel[n] >0, lowestBank-channel[n], 0)
output[n,1] <- (localdepth)*spacing
}
area <- sum(output[,1]) # m^2
print(area)
widthB=sum(output>0)*0.025      # lowest bank to opposite equivalent height
widthB
#get the column name (channel_transect)
title=toString(i)
title
WDA=rbind(widthA, widthB, depth, area)
write.csv2(WDA, file = paste0(wd, '/data/output/','WDA_Trans', title, '.csv'))
}
colnames(read2019)
read2019$TransectNr)
read2019$TransectNr
unique(read2019$TransectNr)
listTransectNumber=(unique(read2019$TransectNr))
listTransectNumber
for (i in listTransectNumber){
oneTransect = read2019 %>% filter(TransectNr == i)
plot(oneTransect[,9], oneTransect[,7])
id <- identify(oneTransect[,9], oneTransect[,7], n=2, labels=oneTransect[,9])
abline(v = oneTransect[id[1],9])
abline(v = oneTransect[id[2],9])
yline = min(oneTransect[c(id[1],id[2]), 7])
abline(h= yline)
channel <- oneTransect[id[1]:id[2], 7]
channel
#points(oneTransect[id[1]:id[2]], channel, col = 'red')
# calculate width between 2 channel edges in meters
widthA <- (max(oneTransect[id[1]:id[2],9])-min(oneTransect[id[1]:id[2],9]))/1000
widthA
# calculate index of deepest point in meters
depth <- min(oneTransect[id[1]:id[2],7])
depth
abline(h = depth)
# get corresponding x-axis value
#indexOfDepth <- subset(oneTransect[,1], oneTransect[,7] == depth)
#indexOfDepth
# calculate area (only below level of lowest bank) in meters^2
lowestBank <- min(oneTransect[c(id[1],id[2]), 7])
spacing <- 0.025
output <- data.frame(matrix(NA, length(channel),1))
for (n in 1:length(channel)){
# n = 1
localdepth=ifelse(lowestBank-channel[n] >0, lowestBank-channel[n], 0)
output[n,1] <- (localdepth)*spacing
}
area <- sum(output[,1]) # m^2
print(area)
widthB=sum(output>0)*0.025      # lowest bank to opposite equivalent height
widthB
#get the column name (channel_transect)
title=toString(i)
title
WDA=rbind(widthA, widthB, depth, area)
write.csv2(WDA, file = paste0(wd, '/data/output/','WDA_Trans', title, '.csv'))
}
read2019 %>% filter(TransectNr == i)
TransectNr
read2019
i=1
i=1
read2019 %>% filter(TransectNr == i)
filter?
?filter
# i=1
oneTransect = read2019 %>% filter(read2019, TransectNr == i)
read2019 %>% filter(TransectNr == i)
colnames(read2019)
TransectNr == i
read2019
# i=1
oneTransect = read2019 %>% filter(TransectNr == i)
View(read2019)
read2019$TransectNr
# i=1
oneTransect = read2019 %>% filter(read2019$TransectNr == i)
oneTransect
plot(oneTransect[,9], oneTransect[,7])
plot(oneTransect[,9], oneTransect[,7])
# i=1
oneTransect = read2019 %>% filter(read2019$TransectNr == i)
oneTransect
read2019
oneTransect[,9]
i
read2019 %>% filter(TransectNr == i)
read2019
oneTransect = read2019 %>% filter(OBJECTID == i) # read the correct column
oneTransect = read2019 %>% filter(name == i) # read the correct column
read2019$TransectNr == 1
oneTransect = read2019 %>% filter(TransectNr == i) # read the correct column
oneTransect = read2019 %>% filter(read2019, TransectNr == i) # read the correct column
read2019[TransectNr == i,]
oneTransect = read2019['TransectNr' == i,] #read2019 %>% filter(read2019, TransectNr == i) # read the correct column
oneTransect
'TransectNr' == i
oneTransect = read2019 %>% filter('TransectNr' == i) # read the correct column
oneTransect
#"U:/Suriname/R/transects_tessa/data/PointsMerge2019ALL_csv.csv"
read2019=read.csv(CSV2019,stringsAsFactors = FALSE, header = TRUE, ",")
read2019
#plot all transects. Col9=distance, col7=Z
plot(read2019[,9], read2019[,7])   #not yet divided into separate series
#plot one transect
i=1
listTransectNumber=(unique(read2019$TransectNr))
listTransectNumber
i=1
oneTransect = read2019 %>% filter('TransectNr' == i) # read the correct column
oneTransect = read2019 %>% filter(TransectNr == i) # read the correct column
oneTransect
#"U:/Suriname/R/transects_tessa/data/PointsMerge2019ALL_csv.csv"
read2019=read.csv(CSV2019,stringsAsFactors = FALSE, header = TRUE, ",", na.strings=c("","NA"))
oneTransect = read2019 %>% filter(TransectNr == i) # read the correct column
oneTransect = read2019 %>% dplyr::filter(TransectNr == i) # read the correct column
oneTransect
plot(oneTransect[,9], oneTransect[,7])
id <- identify(oneTransect[,9], oneTransect[,7], n=2, labels=oneTransect[,9])
abline(v = oneTransect[id[1],9])
abline(v = oneTransect[id[2],9])
yline = min(oneTransect[c(id[1],id[2]), 7])
abline(h= yline)
channel <- oneTransect[id[1]:id[2], 7]
channel
#points(oneTransect[id[1]:id[2]], channel, col = 'red')
# calculate width between 2 channel edges in meters
widthA <- (max(oneTransect[id[1]:id[2],9])-min(oneTransect[id[1]:id[2],9]))/1000
widthA
# calculate index of deepest point in meters
depth <- min(oneTransect[id[1]:id[2],7])
depth
abline(h = depth)
# calculate area (only below level of lowest bank) in meters^2
lowestBank <- min(oneTransect[c(id[1],id[2]), 7])
lowestBank
spacing <- 0.025
output <- data.frame(matrix(NA, length(channel),1))
for (n in 1:length(channel)){
# n = 1
localdepth=ifelse(lowestBank-channel[n] >0, lowestBank-channel[n], 0)
output[n,1] <- (localdepth)*spacing
}
area <- sum(output[,1]) # m^2
print(area)
widthB=sum(output>0)*0.025      # lowest bank to opposite equivalent height
widthB
#get the column name (channel_transect)
title=toString(i)
title
WDA=rbind(widthA, widthB, depth, area)
WDA
############################### Combine Data #################################
big_data=do.call(rbind, datalist)
?filter
oneTransect
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
## ---------------------------
source("./src/functions.R")
## ---------------------------
mapviewOptions(basemaps = c( "Esri.WorldImagery","Esri.WorldShadedRelief", "OpenStreetMap.DE"))
dataFolder <- './data/raw'
years <- c('2018', '2019')
# transect  <- readOGR(paste0(dataFolder, '/transects'), '2009_WnZ_transect')
# select folders
folderSelect <- as.matrix(list.files(paste0(dataFolder, '/GEE_exports'), full.names = T))
df <- rewrite(folderSelect);
# only csv's
df <- df[grep('.csv', folderSelect, ignore.case = T),]
filtered <- vector('list', 100)
for (q in seq_along(years)) {
# q <- 1
year = years[q]
filters = c(year)
filtered = rbind(filtered, df %>%
dplyr::filter(
filters %>%
# apply the filter of all the text rows for each pattern
# you'll get one list of logical by pattern ignored_string
purrr::map(~ to_keep(.x, text = text)) %>%
# get a logical vector of rows to keep
purrr::pmap_lgl(all)
))
}
filtered <- unique(filtered)[1:2,]
allFiles <- do.call(rbind, lapply(as.matrix(filtered)[,1], function(x) read.csv(x, stringsAsFactors = FALSE,
sep = ',', na.strings=c("","NA")
)))
dates <- col_of_interest(allFiles, 'DATE_ACQUIRED$')
coastDist <- col_of_interest(allFiles, 'coastDist$')
# all unique dates
uniqueDates <- unique(allFiles[,dates]);
# all unique transect (id's)
pos <- unique(allFiles[, col_of_interest(allFiles, 'pos$')]);
uniqueX<- unique(allFiles[, col_of_interest(allFiles, 'originX$')]);
uniqueY<- unique(allFiles[, col_of_interest(allFiles, 'originY$')]);
geo<- unique(allFiles[, col_of_interest(allFiles, '.geo')]);
# test simple 2d plot coastline dist
pos_to_test <- c('199000')
testPos <- subset(allFiles, allFiles[,col_of_interest(allFiles, 'pos')] == pos_to_test
& allFiles[,col_of_interest(allFiles, 'coastDist$')] >= 0 )
testPos <- testPos[order(testPos$DATE_ACQUIRED),] #order by date
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
#' set working directory for Mac and PC
wd<-getwd()
rm(list = ls())
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
## ---------------------------
#'
#' Script name: Plot offshore boundary results
#'
#' Short Description:
#'
#'
#' Author: Job de Vries
#'
#' Date Created: 2020-11-16
#'
#' Copyright (c) Job de Vries, 2020
#' Email: j.devries4@uu.nl
#'
## ---------------------------
#'
#' Description
#'
#'
#'
## ---------------------------
rm(list = ls())
#' set working directory for Mac and PC
wd<-getwd()
# setwd("I:/BackUp_D_mangroMud_202001/Research/Software/Projects/offshore_boundary")
## ---------------------------
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
memory.limit(30000000)     # this is needed on some PCs to increase memory allowance, but has no impact on macs.
#  Map view options:
# https://r-spatial.github.io/mapview/articles/articles/mapview_02-advanced.html
## ---------------------------
#' load up the packages
source("./src/packages.R")       # loads up all the packages we need
remotes::install_github("r-spatial/rgee")
# # library(plyr)
# # library(ggridges)
# remotes::install_github("r-spatial/rgee")
remove.packages('Rcpp')
remotes::install_github("r-spatial/rgee")
remotes::install_github("r-spatial/rgee")
.libPaths()
